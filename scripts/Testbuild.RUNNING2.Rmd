---
title:  | 
  |
  | Auto-Psych R Shiny Tool Output
  |
  |
  |
  |
  |
  |
  | 
  | Automated Psychometric Analysis
  | One Parameter Logistic Model [1PLM] Report
  | 
  |
  |
  | 
  | Technical Report, version 1PLM_Auto-Psych_1.0
  |
  |
  | 
  |
  |
  | 
  | 
author: Created by Drs Matthew Courtney (PhD, Ed), Xxxxx Xxxxx (PhD, Xx), & Xxxxxx Xxxxx (PhD, Xx)

output: pdf_document
includes:
      in_header: \usepackage{longtable}

date: "`r format(Sys.time(), 'Report produced: %B %d, %Y, %H:%M:%OS')`" 
 
params:
  datapath: NA
  recommendations: NA
  construct: NA
  population: NA
  constraint: NA
  disc.threshold: NA
  ci.level: NA
  NA.Delete: NA
  p.fit.threshold: NA
  node.sequence.1: NA
  node.sequence.2: NA
  node.sequence.3: NA
  conv: NA
  maxiter: NA
  color.choice: NA
  binwidth: NA 
  rendered_by_shiny: FALSE
  
header-includes:
- \usepackage{longtable}
- \usepackage{booktabs}
- \usepackage{colortbl}
  
---
  
\fontfamily{cmss}
\fontsize{14}{12}
\fontseries{b}
\selectfont

\newpage

\setcounter{tocdepth}{4}
\tableofcontents  
 
 
```{r CHUNK1 Input parameters, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
#### 1. Initial start time and data ####
start.time <- Sys.time()
resp <- read.csv(params$datapath)

#### 2. Report settings ####
Recommendations <- params$recommendations
Construct <- params$construct
Population <- params$population
constraint <- params$constraint
disc.threshold <- params$disc.threshold
ci.level <- params$ci.level
NA.Delete <- params$NA.Delete
p.fit.threshold <- params$p.fit.threshold
node.sequence <- seq(params$node.sequence.1, params$node.sequence.2, len= params$node.sequence.3)
conv <- params$conv
maxiter <- params$maxiter
color.choice <- params$color.choice
binwidth <- params$binwidth

#### 3. Capitalization of construct ####
Construct.C <- toupper(Construct) 

#### 4. Extract full item names ####
Full.Item.Names <- colnames(resp)

#### 5. Use abbreviated names in some places in report ####
Item.Names <- paste("I" , 1:ncol(resp), sep = "-")

#### 6. Obtain number of items for embedded reporting for APA
ncol.english <- ncol(resp)
if(ncol.english > 0 & ncol.english < 10){
 ncol.english <- as.character(english::as.english(ncol.english))
}

#### 7. Give rendering progress in UI to communicate with user throughout report ####
if (params$rendered_by_shiny){
    shiny::setProgress(0.02)
}
```
  
```{r CHUNK2 Load packages, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
#### 1. Load packages ####
library("tinytex")
library("scales")
library("CTT")
library("TAM")
library("sirt")
library("WrightMap")
library("compare")
library("psych")
library("dplyr")
library("knitr")
library("ggplot2")
library("yaml")
library("plyr")
library("kableExtra")
library("ShinyItemAnalysis")
library("cowplot")
library("bookdown")
library("english")
library("xtable")
library("Hmisc")
library("psychometric")
library("plotly")
library("Thermimage")
library("openxlsx")
library("rmarkdown")
library("reshape2")

if (params$rendered_by_shiny){
    shiny::setProgress(0.04)
}

#### use 'option t ††' to denote instances of embedded narrations if useful ####
```
  
```{r CHUNK3 Missing value analysis, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
#### 1. Simplified MVA for total missing % ####
MCAR.tot.miss <- sum(is.na(resp))
MCAR.tot.resp <- nrow(resp) * ncol(resp)
MCAR.perc <- round((MCAR.tot.miss / (MCAR.tot.resp)) * 100, 2)

#### 2. Give numeric word ####
if(MCAR.tot.miss > 0 & MCAR.tot.miss < 10){
 MCAR.tot.miss <- as.character(english::as.english(MCAR.tot.miss))
}

#### 3. If zero, replace with "none" for language coherence in text ####
if(MCAR.tot.miss == 0){
   MCAR.tot.miss <- "none"
}

if (params$rendered_by_shiny){
  shiny::setProgress(0.06)
}
```
  
```{r CHUNK4 Internal consistency freq table and max for item, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
#### 1. Do CTT reliability with NAs replaced with zeros ####
r <- reliability(resp, NA.Delete = NA.Delete)  # User chooses option
Cronbachs <- round(r$alpha, 2)

#### 2. Generate data for frequency table ####
n <- 1
for(n in 1:ncol(resp)){
  freq <- transform(table(resp[, n]))
  names(freq) <- c("category", names(resp)[n])
  assign(paste("freq", n, sep = ""), freq)
}

#### 3. Combine frequency table ####
freq.uneven <- Reduce(function(x, y) merge(x, y, by = "category", all.x = TRUE, all.y = TRUE), mget(paste("freq", 1:ncol(resp), sep = "")))

#### 4. Make table display vertically ####
freq.uneven <- t(freq.uneven)
freq.titles <- freq.uneven[1, ]                         
freq.titles <- as.character(freq.titles)               
freq.uneven <- freq.uneven[2:nrow(freq.uneven), ]      
colnames(freq.uneven) <- freq.titles
freq.uneven <- as.data.frame(freq.uneven)
rownames(freq.uneven) <- colnames(resp)

# replace NAs with blanks for visual for table
freq.uneven <- sapply(freq.uneven, as.character)
freq.uneven[is.na(freq.uneven)] <- ""
print(freq.uneven)
rownames(freq.uneven) <- colnames(resp)

#### 5. Find maximum item scores from item response matrix ####
max.score.item.vector <- apply(resp, 2, max, na.rm = TRUE)
max.raw <- sum(max.score.item.vector, na.rm = TRUE)

if (params$rendered_by_shiny){
  shiny::setProgress(0.08)
}
```

```{r CHUNK5 Observed stats for persons, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
#### 1. Find observed mean and SD for students ####
Scoring <- apply(resp, 1, sum, na.rm=TRUE)
mean.total <- round(mean(Scoring), 2)
sd.total <- round(sd(Scoring), 2)

if (params$rendered_by_shiny){
  shiny::setProgress(0.10)
}
```
  
```{r CHUNK6 Item descriptions, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
#### 1. Item abbreviation and full description
Item.table <- cbind(Item.Names, Full.Item.Names)
Item.table <- as.data.frame(Item.table)
names(Item.table) <- c("Item abbreviation", "Full item description")

if (params$rendered_by_shiny){
  shiny::setProgress(0.12)
}
```
  
```{r CHUNK7 Correlations, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
#### 1. Point biserial item-rest correlations (for imebedded reporting) ####
non.round.disc <- disc <- r$pBis
min.disc <- round(min(disc), 2)
max.disc <- round(max(disc), 2)

#### 2. Round item-rest point biserial correlations to 3dp for reporting in table ####
disc <- round(non.round.disc,3)
disc.table1 <- rbind(Item.Names,disc)
disc.table <- as.data.frame(disc.table1)
disc.table <- disc.table[2,]

#### 3. Round item-total point-biserial correlations to 3dp for reporting in table ####
disc1 <- r$bis
disc1 <- round(disc1, 2)
disc.table1 <- rbind(Item.Names, disc1)
disc.table1 <- as.data.frame(disc.table1)
disc.table1 <- disc.table1[2, ]

#### 4. Identify confidence intervals for point biserial/Pearson correlations (use non-rounded values) ####
Cor.CIs <- lapply(non.round.disc, FUN=function(x)psychometric::CIr(x, nrow(resp), level = ci.level))
Cor.CIs <- as.data.frame(Cor.CIs)
Cor.HiCI <-  unlist(unname(as.vector(round(Cor.CIs[2, ], 3))))
Cor.LowCI <- unlist(unname(as.vector(round(Cor.CIs[1, ], 3))))

#### 5. Create df for table ####
disc.disc1 <- cbind.data.frame(Item.Names, disc, Cor.LowCI, Cor.HiCI, disc1)
#disc.disc1 <- cbind.data.frame(Item.Names, disc, disc1)
names(disc.disc1)<- c("Item Abbreviation","Point Biserial or Pearson", "Lower CI", "Upper CI", "Bi- or Poly-serial")

if (params$rendered_by_shiny){
  shiny::setProgress(0.14)
}
```

```{r CHUNK8 Items lower discrimination threshold, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
#### 1. Identify number of elements under discrimination threshold for embedded summary ####
poor.disc.n <- sum(disc < disc.threshold, na.rm = TRUE)

#### 2. Change to English ####
poor.disc.n.Eng <-  as.character(as.english(poor.disc.n))

#### 3. Create additional rule for instance when = zero ####
if (poor.disc.n.Eng == "zero"){
  poor.disc.n.Eng <- "none"
}

if (params$rendered_by_shiny){
  shiny::setProgress(0.16)
}
```
  
```{r CHUNK9 Correlation matrix, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
#### 1. Create initial matrix ####
Row_Totals <- apply(resp, 1, sum)
resp2 <- cbind(resp, Row_Totals)

#### 2. Modify corstars function: thanks http://www.sthda.com/english/wiki/elegant-correlation-table-using-xtable-r-package ####
corstars <<-function(x, method=c("pearson", "spearman"), removeTriangle=c("upper", "lower"),
                     result=c("none", "html", "latex")){
    # Compute correlation matrix
    x <- as.matrix(x)
    correlation_matrix<-rcorr(x, type=method[1])
    R <- correlation_matrix$r # Matrix of correlation coeficients
    p <- correlation_matrix$P # Matrix of p-value 
    
    ## Define notions for significance levels; spacing is important.
    mystars <- ifelse(p < .0001, "****", ifelse(p < .001, "*** ", ifelse(p < .01, "**  ", ifelse(p < .05, "*   ", "    "))))
    
    ## trunctuate the correlation matrix to two decimal
    R <- format(round(cbind(rep(-1.11, ncol(x)), R), 2))[,-1]
    
    ## build a new matrix that includes the correlations with their apropriate stars
    Rnew <- matrix(paste(R, mystars, sep=""), ncol=ncol(x))
    diag(Rnew) <- paste(diag(R), " ", sep="")
    rownames(Rnew) <- colnames(x)
    colnames(Rnew) <- paste(colnames(x), "", sep="")
    
    ## remove upper triangle of correlation matrix
    if(removeTriangle[1]=="upper"){
      Rnew <- as.matrix(Rnew)
      Rnew[upper.tri(Rnew, diag = TRUE)] <- ""
      Rnew <- as.data.frame(Rnew)
    }
    
    ## remove lower triangle of correlation matrix
    else if(removeTriangle[1]=="lower"){
      Rnew <- as.matrix(Rnew)
      Rnew[lower.tri(Rnew, diag = TRUE)] <- ""
      Rnew <- as.data.frame(Rnew)
    }
    
    ## remove last column and return the correlation matrix
    Rnew <- cbind(Rnew[1:length(Rnew)-1])
    if (result[1]=="none") return(Rnew)
    else{
      if(result[1]=="html") print(xtable(Rnew), type="html")
      else print(xtable(Rnew), type="latex") 
    }
} 

#### 3. Create final correlation matrix with function ####
matrix.r.p <- corstars(resp2)

if (params$rendered_by_shiny){
  shiny::setProgress(0.18)
}
```
  
```{r CHUNK10 Run 1plm mml model, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
#### 1. Run model with Sys.time function to record duration and include conv, maxiter and constraint inputs ####
start.mod.t <- Sys.time()
mod1 <- tam.mml(resp, control=list(nodes=node.sequence, conv = conv, maxiter = maxiter), constraint = constraint)
end.mod.t <- Sys.time()

#### 2. Extract b thresholds ####
thr <- tam.threshold(mod1)
rownames(thr) <- Item.Names
thr<-round(thr, 2)

#### 3. Extract model deviance ####
model.deviance <- round(mod1$deviance, 2)

#### 4. Draw PVs from prior for secondary analysis (written to xlsx file output later) ####
Plausible.values <- TAM::tam.pv(mod1, nplausible=10, ntheta=2000, normal.approx=FALSE) # last three arguments are defaults
Plausible.values <- Plausible.values$pv

if (params$rendered_by_shiny){
    shiny::setProgress(0.20)
}
```
 
```{r CHUNK11 Manage thresholds and Generate WrightMap, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
#### 1. Manage thresholds into WrightMap by creating matrix ####
thr <- as.matrix(thr)
cat.names <- as.character(seq(1:ncol(thr)))
colnames(thr) <- cat.names

#### 2. Obtain SD for thresholds (more descriptive than item difficulty estimate; for embedded reporting) ####
thr.v <- as.vector(thr)               
SD.thresh <- round(sd(thr.v, na.rm=TRUE), 2)

#### 3. Assign step value to each threshold ####
concatenated.cat <- outer(rownames(thr), colnames(thr), function(x, y) paste(x, y, sep = "-"))  # this draws from rows and col names to create names for vector
concatenated.cat <- as.vector(concatenated.cat)     # this creates correct vector of names
names(thr.v) <- concatenated.cat                    # this assigns correct names to numeric vector
thr.v <- thr.v[!is.na(thr.v)]                       # this creates vector of item category difficulties without missing elements

#### 4. Make table ####
numbers <- seq(1:length(thr.v))
names <- names(thr.v)
Wright.descr <- cbind.data.frame(numbers, names, thr.v)
rownames(Wright.descr) <- NULL
colnames(Wright.descr) <- c("Numeric identifier", "Item-category", "difficulty threshold")
Wright.descr <- Wright.descr[order(-Wright.descr$`difficulty threshold`), ]
rownames(Wright.descr) <- NULL

#### 5. Modify gg WrightMap function to apply later in script; thanks ShinyItemAnalysis team ####
ggWrightMapnew <<- function(theta, b, binwidth = 0.3, color = "blue", size = 2, item.names){
  if (missing(theta)){
    stop("'theta' needs to be specified", call. = FALSE)
  }
  if (missing(b)){
    stop("'theta' needs to be specified", call. = FALSE)
  }
  if (missing(item.names)){
    ITEM.NAMES <- 1:length(b)
  } else {
    ITEM.NAMES <- item.names
  }

  df.theta <- data.frame(theta = theta)

  theta.cut.points <- seq(min(c(theta, b)) - binwidth/2, max(c(theta, b)) + binwidth/2, binwidth/2)
  b.cut.points <- cut(b, theta.cut.points, include.lowest = T)
  levels(b.cut.points) <- theta.cut.points[-length(theta.cut.points)] + diff(theta.cut.points)/2
  b.cut.points <- as.numeric(paste(b.cut.points))

  df.b <- data.frame(item = as.character(ITEM.NAMES), b = b, y = b.cut.points)
  df.b$x <- 0
  for (i in unique(df.b$y)){
    n <- nrow(df.b[df.b$y == i, ])
    df.b[df.b$y == i, "x"] <- 1:n
  }

  df.b$item <- as.character(df.b$item)
  maxn <- max(nchar(df.b$item))

  if (missing(item.names)){
    while(any(nchar(df.b$item) < maxn)){
      df.b$item <- ifelse(nchar(df.b$item) < maxn, paste0("0", df.b$item), df.b$item)
    }
  } else {
    df.b$item <- as.character(df.b$item)
    while(any(nchar(df.b$item) < maxn)){
      df.b$item <- ifelse(nchar(df.b$item) < maxn, paste0(" ", df.b$item), df.b$item)
    }
  }

  if(any(df.b$x > 1)){
    for (k in which(df.b$x > 1)){
      df.b[nrow(df.b) + 1, ] <- df.b[k, ]
      df.b[nrow(df.b), "item"] <- "|"
      df.b[nrow(df.b), "x"] <- df.b[nrow(df.b), "x"] - 0.5
    }
  }

  lim.x.min <- min(c(theta, b)) - binwidth
  lim.x.max <- max(c(theta, b)) + binwidth

  g1 <- ggplot(df.theta, aes_string(x = "theta")) + 
    ggtitle("Person Side") +                               # I added this here to the function on person side
    geom_histogram(binwidth = binwidth, fill = color, col = "black", na.rm = TRUE) +
    xlim(lim.x.min, lim.x.max) +
    coord_flip() +
    scale_y_reverse() +
    xlab("Student ability (theta)") +
    theme_app(base_size = size) +
    theme(axis.title.x = element_blank(),
          axis.text.x = element_blank(),
          axis.ticks.x = element_blank())

  g2 <- ggplot(df.b, aes_string(x = "x", y = "y", label = "item")) +
    ggtitle("Item Side") +                                                         # I added this here to the function on item side
    geom_text(hjust = 0.5, vjust = 0.5, na.rm = TRUE, size = 1.8) +                 # I changed here from 0.5 to 0.3; also entered size value to 2 to suit
    scale_y_continuous(position = "right", limits = c(lim.x.min, lim.x.max)) +
    scale_x_continuous(limits = c(min(df.b$x) - 0.5, max(df.b$x) + 0.5)) +
    ylab("Item threshold (delta)") +
    theme_app(base_size = size) +
    theme(axis.title.x = element_blank(),
          axis.text.x = element_blank(),
          axis.ticks.x = element_blank())

  plot_grid(g1, g2)
}
   
if (params$rendered_by_shiny){
  shiny::setProgress(0.22)
}
```
  
```{r CHUNK12 Item difficulty estimates, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
#### 1. Extract information about item difficulty estimates ####
item.difficulties <- round(mod1$item$xsi.item, 2)
mean.item.diff <- round(mean(item.difficulties), 2)
sd.item.diff <- round(sd(item.difficulties), 2)

item.diff.df<-cbind.data.frame(Item.Names,item.difficulties)
names(item.diff.df) <- c("Item Abbreviation", "Item Difficulties")

if (params$rendered_by_shiny){
    shiny::setProgress(0.24)
}
```
 
```{r CHUNK13 Model reliability information, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
#### 1. Extract EAP person ability means and vectors ####
mean.EAP.person <- round(mean(mod1$person$EAP), 2)
EAP.person <- mod1$person$EAP

#### 2. Obtain min, max EAP, variance and reliability for embedded summary ####
EAP.min <- round(min(EAP.person), 2)
EAP.max <- round(max(EAP.person), 2)

EAP.variance <- mod1$variance
EAP.SD <- round(sqrt(EAP.variance), 2)

EAP.reliability <- round(mod1$EAP.rel, 2)
EAP.reliability.percent <- EAP.reliability*100

#### 3. Construct written result for reliability using if, if else rule ####
if (EAP.reliability < .50) {
  alpha.result <- "unacceptable"
} else if (EAP.reliability >= .50 & EAP.reliability < .60) {
  alpha.result <- "poor"
} else if (EAP.reliability >= .60 & EAP.reliability < .70) {
  alpha.result <- "questionable"
} else if (EAP.reliability >= .70 & EAP.reliability < .80) {
  alpha.result <- "acceptable"
} else if (EAP.reliability >= .80 & EAP.reliability < .90) {
  alpha.result <- "good"
} else if (EAP.reliability >= .90) {
  alpha.result <- "excellent"
} else if (EAP.reliability < .99) {
  alpha.result <- "excellent"
}

if (params$rendered_by_shiny){
  shiny::setProgress(0.26)
}
```
  
```{r CHUNK14 Item fit stats, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
#### 1. Extract outfit stats ####
item.fit.mod1 <- msq.itemfit(mod1) 
item.fit.mod2 <- item.fit.mod1$itemfit

outfit <- round(item.fit.mod2$Outfit,2)
outfitt <- round(item.fit.mod2$Outfit_t,2)
outfitp <- item.fit.mod2$Outfit_p                            # no rounding prior to APA formatting

#### 2. Convert outfit p values to APA format with if else rule ####
outfitp <- ifelse(outfitp < .0001, "<.0001", 
                  ifelse(outfitp < .001, "<.001 ", 
                         ifelse(outfitp < .01, "<.01  ", 
                                ifelse(outfitp < .05, "<.05   ", "ns    "))))

#### 3. Extract infit stats ####
infit <- round(item.fit.mod2$Infit,2)
infitt <- round(item.fit.mod2$Infit_t,2)
infitp <- item.fit.mod2$Infit_p                              # no rounding prior to APA formatting

#### 4. Convert infit p values to APA format with if else rule ####
infitp <- ifelse(infitp < .0001, "<.0001", ifelse(infitp < .001, "<.001 ", 
                                                  ifelse(infitp < .01, "<.01  ", 
                                                         ifelse(infitp < .05, "<.05   ", "ns    "))))
#### 5. Bind fit stat data ####
item.fit.stats <- cbind.data.frame(Item.Names, outfit, outfitt, outfitp, infit, infitt, infitp)
names(item.fit.stats) <- c("Item Abbreviation", "Outfit", "Outfit t", "Outfit p", "Infit", "Infit t", "Infit p")
round.item.fit.stats <- item.fit.stats

if (params$rendered_by_shiny){
  shiny::setProgress(0.28)
}
```
  
```{r CHUNK15 Internal consistency rule table, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
#### 1. Create internal consistency rule table for methodology ####
Internal_Consitency <- c("Excellent", "Good", "Acceptable", "Questionable", "Poor", "Unacceptable")
Cronbachs_Alpha <- c("0.90 & up", "0.80-0.89", "0.70-0.79", "0.60-0.69", "0.50-0.59", "under 0.50")
Crony <- as.data.frame(cbind(Internal_Consitency, Cronbachs_Alpha))
colnames(Crony) <- c("Internal Consistency", "Cronbach's alpha")

if (params$rendered_by_shiny){
  shiny::setProgress(0.30)
}
```
  
```{r CHUNK16 WLE Estimates, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
#### 1. Extract WLE estimates to include in the Excel outputs (developer may choose to include, currently excluded from output) ####
Ability.theta <- tam.wle(mod1)$theta

if (params$rendered_by_shiny){
    shiny::setProgress(0.32)
}
```
  
```{r CHUNK17 Color pallette, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
#### 1. Set color pallete for report graphs ####
if (color.choice == "Eurasian Steppe") {
  color.palette <- rep(c("#404F24", "#816C5B", "#493829", "#855723", "#ADB3B8", "#23487A", "#9C7B3A", "#32373E", "#D8BF5B", "#424844"), 200)
} else if (color.choice == "Deep Code") { 
  color.palette <- rep(c("#6C0035", "#2E0F43", "#800007", "#142A20", "#930244", "#0C1826", "#A01B1D", "#150759", "#5E0331", "#322f2C"), 200)
} else if (color.choice == "Commercial Overreach") { 
  color.palette <- rep(c("#99A2AA","#59B17F", "#98D6C3", "#ECAE65", "#FFDCA2",  "#3FA7C2","#7CBDCD","#5D7EBD","#ADCDF0", "#E77052", "#FFA478","#A0D172", "#DAE299", "#EE8889", "#FFBCCC", "#7283BE", "#AFBCE0"), 200) 
} else if (color.choice == "Take a Trip") { 
  color.palette <- rep(c("#75D5FD", "#B76CFD", "#FF2281", "#011FFD", "#FCBC0C", "#FDFF0C", "#39E6D4", "#22FC3D", "#1CA68F", "#CB1021"), 200)
} else if (color.choice == "Pohutukawa Beach") {
  color.palette <- rep(c("#7A5F1C", "#597FA3", "#BE001B", "#4D3A2A", "#767D36", "#360202", "#760D0D", "#3D4816", "#AADDFE", "#9E937B"), 200)
} else if (color.choice == "Southland Coal") {
  color.palette <- rep(c("#2F5380", "#7E6B75", "#8C754D", "#515F80", "#CA6938", "#F7FFB7", "#3985CA", "#764B59", "#616774", "#322f2C"), 200)
}

color.palette <- color.palette[1:length(Item.Names)]

if (params$rendered_by_shiny){
  shiny::setProgress(0.34)
}
```
  
```{r CHUNK18_Set_mnsq_min_and_max_values_for_graphs, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
#### 1. Extract min and max for graph ####
Theoretical.mnsq.max <- 1 + 2 * (sqrt(2/ nrow(resp)))
Theoretical.mnsq.min <- 1 - 2 * (sqrt(2/ nrow(resp)))

if (params$rendered_by_shiny){
    shiny::setProgress(0.36)
}
```
  
```{r CHUNK19_Extract_details_for_polytomous_analysis, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
#### 1. Use TAM ctt function with EAP vector ####
ctt_raw <- tam.ctt(resp, EAP.person)

#### 2. Identify confidence intervals for Pbs values ####
Cor.CIs <- lapply(ctt_raw$rpb.WLE, FUN = function(x)psychometric::CIr(x, nrow(resp), level = .95))
Cor.CIs <- as.data.frame(Cor.CIs)
Cor.HiCI <-  unlist(unname(as.vector(round(Cor.CIs[2, ], 3))))
Cor.LowCI <- unlist(unname(as.vector(round(Cor.CIs[1, ], 3))))

#### 3. Combine data ####
ctt_raw.df <- cbind(ctt_raw[, 4:7], round(ctt_raw[, 8:9], 3), round(Cor.LowCI, 3), round(Cor.HiCI, 3), round(ctt_raw[, 10], 2) )

#### 4. Rename df ####
colnames(ctt_raw.df) <- c("Item", "Total", "Category", "Count", "Percent", "Pbs","Lower 95 CI","Upper 95 CI", "MeanAbility")

#### 5. Identify Pbs disorderedness by first creating max score for items ####
max.score.items <- apply(resp, 2, max)

#### 6.. add 1 to each value as this includes the zero value ####
max.score.items <- max.score.items + 1
CTT_length <- sum(max.score.items)

#### 7. Sum elements of the vector (for final row of each item) ####
cum.sum.categories <- cumsum(max.score.items)

#### 8. Create starting values for rows ####
start.rows <- cum.sum.categories + 1
start.rows <- unname(c(1, start.rows[ - length(start.rows)]))
cum.sum.categories <- unname(cum.sum.categories)    # last row of vector 

#### 9. Split the ctt_raw dataframe by item (split needs to happen to get logical vector to apply to df later) ####
split.data.item <- split(ctt_raw.df$Pbs, ctt_raw.df$Item) 

#### 10. Identify disordered point biserials ####
df.one <- ctt_raw.df[1:5, ]
minus.vector <- -diff(df.one$Pbs)                   # it's a vector of minuses but a positive element identifies problem
minus.vector <- c(minus.vector, -1)                 # it's a vector of minuses but a positive element identifies problem
minus.vector <- minus.vector > 0                    # true = disorderedness

#### 11. apply function on each list element to create large vector ####
result.logical <- lapply(split.data.item, FUN = function(x)c(-diff(x), -1) > 0)

##### 12. Turn list into vector ####
result.logical.v <- unlist(result.logical, use.names = FALSE)

all.categories <- length(result.logical.v)
total.disordered <- sum(result.logical.v)

##### 13. The result.logical.v vector identifies problematic item categories (to be used in table) ####
ctt_raw.df <- cbind(ctt_raw[, 4:7], round(ctt_raw[, 8:9], 3), result.logical.v, round(Cor.LowCI, 3), round(Cor.HiCI, 3), round(ctt_raw[, 10], 2) )

#### 14. Rename df ####
colnames(ctt_raw.df) <- c("Item", "Total", "Category", "Count", "Percent", "Pbs", "Disorderedness T/F", "Lower 95 CI","Upper 95 CI", "MeanAbility")

#### 15. Remove col 8 and 9 as CIs too busy (consider for later) ####
ctt_raw.df <- ctt_raw.df[, -c(8, 9)]

if (params$rendered_by_shiny){
    shiny::setProgress(0.38)
}
```

```{r CHINK20_Person_fit_stats, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
#### 1. Person fit stats for graph/spreadhseets ####
tam.person.fit.stats <- TAM::tam.personfit(mod1) # include outfit for now, look into automating upper and lower limits
Person_fit_stats <- tam.person.fit.stats$outfitPerson

#### 2. Combine personfit stats with EAP data ####
ability.thetas.4.table <- mod1$person$EAP
persfit_theta_resp<-cbind.data.frame(Person_fit_stats,ability.thetas.4.table, resp)
ordered_resp<-persfit_theta_resp[order(-Person_fit_stats), ]

#### 3. Calculate 95% CIs for person fit ####
sum(apply(resp, 2, function(x)max(x, na.rm = T)))
Theoretical.mnsq.maxP <- 1 + 2 * (sqrt(2/ sum(apply(resp, 2, function(x)max(x, na.rm = T))) ))
Theoretical.mnsq.minP <- 1 - 2 * (sqrt(2/ sum(apply(resp, 2, function(x)max(x, na.rm = T))) ))

Theoretical.mnsq.minP <- round(Theoretical.mnsq.minP, 2)
Theoretical.mnsq.maxP <- round(Theoretical.mnsq.maxP, 2)

if (params$rendered_by_shiny){
  shiny::setProgress(0.40)
}
```

\newpage

# INFORMATION PAGE
This is an automatically-generated psychometric technical report based on the item-response data provided. The report includes a description of the general methodology used, descriptive statistics of the data, results for psychometric analysis based on classical test theory and item-response theory, and a summary of key results. If you would like to cite this tool, feel free: 
   
   
   Courtney, M. G. R., Xxxxx, X., & Xxxxxx, X. (XXXX). Auto-psych: a novel shiny app for the psychometric analysis and scoring of assessment and survey data. The X Journal.
 
The main author would like to thank Drs Zhang, Wu, Wilson, McGaw, and Nguyen for their support. This utility can be considered a public good. 
  
  Github repository: XXXXXXXXXXX


\newpage 
 
# TECHNICAL SUMMARY 
This summary provides a review of the results of the psychometric technical report associated with the administration of the `r Construct` assessment on the `r Population`.  
  
A total of `r nrow(resp)` students participated in the `r Construct` exam. The mean overall total (raw) score was `r mean.total` (out of total of `r max.raw`) and the standard deviation of the total score was `r sd.total`. The exam constituted a total `r ncol.english` items (Table 3).  
  
The reliability for the test was `r EAP.reliability` suggestive of `r alpha.result` reliability (with 0.70 as a general acceptable lower limit). This suggests that the test instrument captured `r EAP.reliability.percent`% of the variation in students' true score.
  
Point biserial correlations ranged from `r min.disc` to `r max.disc` and, of the total `r ncol.english` items, `r poor.disc.n.Eng` were under the minimum correlation of `r disc.threshold` (Table 4).  
  
The mean ability (logit) of the sample of interest was `r mean.EAP.person` (with `r constraint` centered) and the associated standard deviation was `r EAP.SD`. The mean item difficulty was `r mean.item.diff` with a standard deviation of `r SD.thresh` (across all item thresholds). Visual inspection of the Wright Map (Figure 3) helps to illustrate test targeting.  
  
# NOTES  
`r Recommendations`.  
  
\newpage
# FULL TECHNICAL REPORT
## 1. PURPOSE
The purpose of this document is to present the methodology and results of the analysis of the student response data for the *`r Construct`* construct. The response data was drawn from a sample of the *`r Population`*, and the *`r Construct`* ability of *`r Population`* was of research interest. Item Response Theory analysis (IRT) was undertaken and a 1 parameter logistic model (1PLM) was applied to the partial credit data.  
  
## 2. ITEMS INCLUDED IN THE `r Construct.C` INSTRUMENT
Table 1 presents the `r ncol(resp)` items included in the `r Construct` instrument:  
  
```{r CHUNK21_Item_table, echo=FALSE, fig.height=7, fig.width=10, message=TRUE, warning=FALSE}
kable(Item.table, format = "latex", booktabs = T, align = 'l', caption = "List of Items", longtable = T) %>%
  kable_styling(latex_options = c("striped", "scale_down", "repeat_header"), font_size = 11)

if (params$rendered_by_shiny){
  shiny::setProgress(0.42)
}
```

\newpage  
  
## 3. METHODOLOGY
### 3.1 Missing Value Analysis
Missing Value Analysis (MVA) is used to assess the extent to which data is missing in the current data. This is reported in terms of total percentage of responses missing in the entire dataset.
  
### 3.2 Instrument Reliability
Instrument reliability is theoretically conceived as the proportion of true score variance $Var[T]$ to observed score variance $Var[O]$,  
  
\begin{equation}
Reliability = \frac{Var[T]}{Var[O]}
\end{equation}
  
Because it is impossible to identify the proportion of variance due to true scores, we can only estimate this value. Derived from Generalisability Theory (Brennan, 2001), the following formula is often applied to estimate the reliability of a test instrument,  

\begin{equation}
Reliability =\frac{Var[O]-Var[E]}{Var[O]}
\end{equation}
 
where $Var[O]$ represents the amount of observed variation in ability, and $Var[E]$ represents the amount of variation due to error. Equivalent to the formula above, the formula for the Cronbach's alpha coefficient (Cronbach, 1951) is expressed as follows,  
  
\begin{equation}
\alpha =\frac{K\bar{c}}{(1+(K-1)\bar{c})}
\end{equation}  
  
where $K$ is the number of items, and $\bar{c}$ is the average of all the covariances between all items.  
In accordance with DeVellis (2012, pp. 109-110), Table 2 presents some general rules-of-thumb for interpreting the meaning of the alpha $\alpha$ coefficient for a test instrument.  
  
```{r CHUNK22_Internal_consistency_table, echo=FALSE, fig.height=7, fig.width=10, message=TRUE, warning=FALSE}
kable(Crony, "latex", booktabs = T, align = 'l', caption = "Interpreting the Cronbach's Alpha") %>% 
  kable_styling(latex_options = c("striped"), font_size = 11)

if (params$rendered_by_shiny){
  shiny::setProgress(0.44)
}
```
  
It should be noted that the Cronbach's $\alpha$ coefficient assumes an equivalent contribution of each item to the total score (tau, $\tau$, equivalence), consequently the $\alpha$ coefficient is considered lower bound estimate of reliability. Based on the 1PLM undertaken, the expected *a posteriori* (EAP; Bock & Aitken, 1981) estimate (for the individual scores; see subsection 3.4) for instrument reliability is also estimated.
  
### 3.3 Item Discrimination
The discrimination indices (correlation coefficients) provide an estimate of the contribution of each item to the construct of interest, `r Construct`. The indices for each item were estimated by ommiting each item-of-interest's contribution to the summed totals (often termed the item-rest correlations). This was done because inclusion of the item of interest in the summed total score artificially inflates each discrimination index. The lower limit for flagging potentially low discriminating items was set at `r disc.threshold`.  
  
Because Pearson correlations provide attenuated estimates of the relationships involving categoric variables, polyserial correlations (and biserial correlations for dichotomous items) are also included as a means to assess item discrimination (Olsson, Drasgow, & Dorans, 1982). Correlations are interpreted as small ($r>.10$), medium ($r>.30$) and large ($r>.50$) in accordance with Cohen (1992). In addition, 95% confidence intervals (CIs) are produced for each item-rest Pearson/point bi-serial discrimination index. These are done in accordance with COhen, Cohen, West, and Aiken (2003). Where lower 95% CI for items are zero or below zero, these items should be flagged.  
  
To assess the degree to which each discrimination index is inflated due to the inclusion of the item of interest, a full Pearson item-total correlation matrix is also generated in Appendix A.  
  
### 3.4 Item-Response Theory Analysis
#### 3.4.1 The one-parameter logistic model   
\hfill\break
IRT analysis was undertaken with the assistance of the $TAM$ package ($version\hspace{.1cm}2.10{\text -}24$; Robitzsch, Kiefer, & Wu, 2018). When item-response data is dichotomous, a one-paramters logistic item response model can applied to the data where,  
  
\begin{equation}
P(x_{ni}=1|\theta_n,\delta_i)=\frac{e^{a(\theta_n-\delta_i)}}{1+e^{a(\theta_n-\delta_i)}}
\end{equation}  
  
\vspace{4mm}

where $\theta_n$ the person ability, $\delta_i$ is the item difficulty, and $a$ is the discrimination factor for approximating the Rasch ogive.  
  
However, in the case of polytomous item response data, a partial credit model is applied (see Masters, 1982). The Partial Credit Model (PCM; Masters, 1982) can be denoted as,  
  
\begin{equation}
P(x_{ni}=x|\theta_n,\delta_{ik}) = \frac{e^{\sum_{k=0}^{x} (a(\theta_{n}-\delta_{ik}))}} {\sum_{j=0}^{ki}e^ {\sum_{k=0}^{j}(a(\theta_{n}-\delta_{ik}))}}, x=0,1,2,... k
\end{equation} 
  
where, $P(x_{ni}=x|\theta_n,\delta_ik)$ is the probability of a person whose $\theta_{n}$ responding in category $x$ of item $i$ where $\delta_{ik}$ is the difficulty of the step threshold that governs the probability of the response befalling in category $x$ rather than category $x-1$, $j$ is the performance level in item $i$, and $a$ is the discrimination factor for approximating the Rasch ogive.  
  
Marginal maximum likelihood (MMLE) estimation (Bock & Aitkin, 1981) was used as this estimation method has been shown to produce more stable person and item estimates related to the associated population. In addition to the one-parameter logistic item response mode presented above, it is assumed that $\theta$ follows a prior normal distribution in the population (Wu, Tam, Jen, 2016). When this form of analysis is undertaken, the specific ability levels of the sample in question is not of focus (Wu, Tam, & Jen, 2016, p. 262), however point estimates for individual students in the sample (defined as expected *a posteriori*, EAP, ability estimates; the mean of the posterior distribution) are be estimated in a two-step process. To do this, the item difficulties are first estimated via MML estimation. Thereafter, based on these specific item difficulties, the sample-specific EAP ability point estimates are then estimated. In the aforementioned $TAM$ package ($version\hspace{.1cm}2.10{\text -}24$), the EAP point ability estimates are based on the mode of the likelihood function. Warm's (1989) Weighted Likelihood estimation (WLE) method uses the mean of the likelihood function providing for a more precise method of estimating person point ability. In the $TAM$ package, Warm's point ability estimates and associated reliability estimates are also estimated (after the parameters for the 1plm have been established). However, primarily, EAP estimates are primarily interpreted in this investigation.  
  
#### 3.4.2 IRT estimates of reliability  
\hfill\break
According to Robitzsch, Kiefer, and Wu (2018), if we let $v$ denote the variance of theta ($\theta$) estimates and let $s$ denote the average of the squared error for those estimates, then, the EAP reliability is defined as $v/(v+s)$, while the WLE reliability is defined as $(v-s)/v$. Therefore, the EAP formula sums total variance in the denominator.  
  
#### 3.4.3 Note on secondary analysis of data  
\hfill\break 
Despite the precision with which the EAP ability estimates can be determined, their inclusion in secondary models designed to gauge differential achievement patterns within different educational ecologies is not appropriate. For such research questions, plausible values (PVs) should be used. Plausible values are random draws from students’ posterior distribution (Wu, Tam, & Jen, 2016, p. 280), and it is these values that are better suited for secondary analysts to include in statistical models designed to test distributive achievement patterns in classrooms, schools, and broader demographic ecologies (Wu, Tam, & Jen). For example, a secondary analysis may be interested in the degree to which student ability was influenced by school mean socio-economic status. To undertake this level of analysis, at least five different plausible value samples should drawn. Thereafter, five respective multilevel models (MLMs) should be run and the average result for relevant intercepts, fixed effects, and variance components should be determined (Wu, 2005; Laukaityte & Wiberg, 2017).  
  
#### 3.4.4 Interpreting item-fit statistics  
\hfill\break
Analysis for the item-response matrix included both item infit (information weighted) and item outfit (not information weighted) statistics. The unweighted item-fit statistics (specific to the dichotomous model) are provided as follows,

\begin{equation}
fit_{unwt} = \frac{1}{N}\sum_{n}^{}\frac{(x_{ni}-E(X_{ni}))^2}{Var(X_{ni})}
\end{equation}  

whereas the weighted (infit) item statistics are provided as follows,  
  
\begin{equation}
fit_{wt} = \frac{\sum_n (x_{ni}-E(X_{ni}))^2}{\sum_n Var(X_{ni})}
\end{equation}  
  
where, $x_{ni}$ is the observed score for each $n$ person for each item $i$, $E(X_{ni})$ represents the expected or theoretical expectation for the respective observed score, and the $Var(X_{ni})$ is given by $P_{ni}(1-P_{ni})$ which represents the variance asscoated with each item ($i$) person ($n$) response. Unlike the item outfit statistic ($fit_{unwt}$), the item infit statistic $fit_{wt}$ identifies an average degree of variance for each item (see denominator, $\sum_n Var(X_{ni})$).  
  
To interpret itemfit statistics, the confidence interval for the item outfit distribution is also included in the associated results section. The 95% confidence intervals for the fit statistics were estimated in accordance with Wu, Tam, and Jen (2016, p. 148),  
  
\begin{equation}
95\hspace{.1cm}percent\hspace{.1cm}CI=1\pm2\sqrt{\frac{2}{N}}
\end{equation}
 
\vspace{4mm}

where, $CI$ is the confidence interval, and $N$ is the number of students in the sample. Items below the 95% confidence interval 
interval (i.e., under 0.80 when *N* is 200) could be considered over-fitting (relative to the other items analysed). Items above the 95% confidence interval could be considered relatively underfitting. Important to note is that overfitting items are generally not problematic (see Wu, Tam, & Jen, 2016, pp. 151-153) and should be retained. See Masters (1988) for exceptional circumstances when test equating across certain demographic subgroups is of primary research interest. In formula 8, $N$ can be replaced by $I$, with $I$ representing the total number of items (or instances of test information, in the case of partial credit scoring), for an analysis of person outfit. This analysis is also undertaken in this report.  
  
In addition to fit statistics for each item, an estimate of the extent to which the entire model deviates from the observed scores can also be ascertained. This is known as model deviance and is also reported in the subsection on item fit. An assessment of change in deviance can be undertaken when comparing different models for the same data.  
  
#### 3.4.5 Alpha when deleted reliability estimate  
\hfill\break
One way to assess the performance of an underfitting (often also low discriminating) item is to assess the change in the reliability coefficient when the item is removed. If, upon removal of the item from analysis, the test reliability increases (i.e., Cronbach's $\alpha$ increases), there is further evidence in support of the item's limited contribution to the construct. Therefore, if the $\alpha_{deleted}$ is larger than the $\alpha_{full}$, the item should be flagged and possibly deleted.  
  
#### 3.4.6 Wright maps  
\hfill\break
A Wright map provides a means of assessing the relative distribution of person abilities and item difficulties. If the item is dichotomous (i.e., correct/incorrect), the position of the question on the Wright Map (right side, Item deltas) represents the point at which the student has a 50% chance of achieving the question. If the item is polytomous (partial credit), two or more Thurstonian thresholds are illustrated on the right side of the graph. In this instance, each Thurstonian threshold represents the point where a student has a 50% chance of achieving at least the indicated level of performance on an item.  
#### 3.4.7 Item expected score curves  
\hfill\break
Item expected score curves illustrate the difference between the observed and expected student ability for each item. For polytomous items, the $Y$ axis for these graphs represent the maximum score for that item. It is expected that as student ability increases, observed responses would follow a similar pattern. Major discepencies between these patterns provide insight into where the item may be functioning in an unexpected way.  
  
#### 3.4.8 Item category expected score curves  
\hfill\break
Item category expected score curves are also provided. Each of these graphs illustrate the probability, across levels of theta, for achieving each category (as oppossed to achieving a zero). The $Y$ axis in this instance ranges from 0 to 1.00 in accordance with the step for each category. While thresholds will generally be ordered across categories, this may not be the case when a the probability of a middle-category, between 1 and $s$ (with $s$ representing the maximum partial credit for that item).  
  
#### 3.4.8 Classical item analysis  
\hfill\break
Another more conservative means of assessing item functioning is to examine the correlation between item categories and estimated student ability (see Adams, Wu, & Wilson, 2019, $itenal$ analysis). Let's use the example of a polytomous item with categories 0, 1, and 2. If category 0 was coded 1 and all other categories coded zero, one would expect a more negative correlation between the category and the item. If category 2 was coded 1 and all other items were coded zero, one would expect a more positive correlation. Furthermore, if category 1 was coded 1 and all other categories coded 0, we would expect a correlation coefficient between the two previously estimated ones. Therefore, for categories 0, 1, and 2, we might expect correlation coefficients of the following sequence; -0.3, to -0.1 to 0.1; respectively. To assess the degree of disorderedness, upper and lower confidence intervals (CIs) are produced for each point bi-serial correlation (Cohen et al., 2003). For this analysis, a confidence level of `r ci.level` was chosen. If for example correlation coefficients for categories 0, 1, and 2 are -0.30 (CIs: -0.25, **-0.35**$^*$), -0.32 (CIs: **-0.27**$^*$, -0.37), and 0.1 (CIs: -0.05, -0.15), this would not be considered problematic as the CIs suggest that within the bounds of the 95% CIs, it is possible that the point biserials are ordered (refer to bold values$^*$).  
  
#### 3.4.9 Test information and standard error curves  
\hfill\break
The amount of information that a test provides about the test sample (and associated population) is dependent upon both test targeting, and the number of pieces of test information. The amount of information is maximised when the average student score approaches zero logits (with items centred). Total test information is also increased as the number of individual pieces of test information increase. For example, while a dichotomous item provides one piece of test information, a polytomous item (scored 0, 1, & 2) provides two pieces of test information. Test more test information available for a given theta, the more precise an estimate. Therefore, the standard error associated with each student's estimated level of ability can be considered the inverse of the test information function. Both the test information function and standard errors are presented in this manuscript.  
  
#### 3.4.10 Outfit mean square person fit statistics  
\hfill\break
Outfit MNSQ (mean square) person fit statistics are also generated for the purpose of identifying anomolous person response patterns. Respondents with higher person outfit statistics well above 1.00 could be considered underfitting the model. These respondents would likely be those with very high overall ability whom performed unusually poorly on easier items. Respondents with lower person outfit statistics well below 1.00 would be those performing in a very predictable way, perhaps those reaching the very top score for each question.  
  
### 3.5 Statistical packages  
Analysis was undertaken with the assistance of the $CTT$ ($version\hspace{.1cm}2.3.2$; Willse, 2018), $psych$ ($version\hspace{.1cm}1.8.4$; Revelle, 2018), $TAM$ ($version\hspace{.1cm}2.10{\text -}24$; Robitzsch, Kiefer, & Wu, 2018), $xtable$ ($version\hspace{.1cm}1.8{\text -}3$; Dahl, Scott, Roosen, Magnusson & Swinton, 2018), $Hmisc$ ($version\hspace{.1cm}4.1{\text -}1$; Harrell & Dupont, 2018), and $ShinyItemAnalysis$ ($version\hspace{.1cm}1.3.0$; Martinková & Drabinová, 2018) R packages.  
  
The $CTT$ package provided results pertaining to the frequency of response categories, point biserial (Pearson) discrimination indices, poly- and bi-serial discrimination indices, the Cronbach's alpha ($\alpha$) reliability coefficient, and the classical test theory statistics including the . The $xtable$ and $Hmisc$ packages provided results pertaining to the full Pearson correlation matrix (between all items). The $TAM$ package was used to carry out the 1PLM model for the partial credit data. Finally, the $ShinyItemAnalysis$ package provided a visual illustration for the relative positions of question items and person abilities.  
  
\newpage
  
## 4. RESULTS  

\newpage
   
### 4.1 Missing Value Analysis Results  
Missing value analysis was undertaken on the `r Construct` dataset. Of the total `r MCAR.tot.resp` item responses in the matrix, `r MCAR.tot.miss` were missing (`r MCAR.perc`% of all responses). Table 10 (Appendix A7) provides a breakdown of missingness for each item in the dataset.  
  
### 4.2 Observed Scores  
A total `r nrow(resp)` students participated in the `r Construct` assessment. The mean overall total score was `r mean.total` and the standard deviation of the total score was `r sd.total`. The maximum raw score was `r max.raw`. The frequency of categories for the partial credit items is given in Table 3.  
\vspace{2mm}  
  
```{r CHUNK23_Frequency_of_Cat, echo=FALSE, message=TRUE, warning=FALSE}
kable(freq.uneven, format = "latex", booktabs = T, align = 'cc', caption = "Frequency of Categories for Each Item", longtable = T) %>%
  kable_styling(latex_options = c("striped","repeat_header"), font_size = 11)

if (params$rendered_by_shiny){
  shiny::setProgress(0.46)
}
```
  
\newpage  
  
### 4.3 Point Biserial Discrimination Indices  
The `r ncol(resp) ` point bi-serial and poly-serial discrimination indices are included Table 4. Note that for both 'Point Biserial or Pearson'  and 'Bi- or Poly-serial' correlations, the item's contribution is removed from the total (see Appendix A1, Full Pearson Correlation Matrix, for discrimination indices that include the contribution from the item of interest--final row of matrix). Item-rest correlation coefficients under the pre-defined lower limit of `r disc.threshold` are in blue while negative item-rest correlations are in red. Note that the upper and lower `r ci.level`% confidence intervals are also presented in Table 4 for each item.  
  
\newpage  
  
```{r CHUNK24_Discrimination_table, echo=FALSE, fig.height=7, fig.width=10, message=TRUE, warning=FALSE}
disc.disc1 %>%                                                           
  dplyr::mutate(                                                      # mutate function enables the piping of extra coloring info into the table
    `Item Abbreviation` = disc.disc1$`Item Abbreviation`,             # simply defines the first column of the variable to be selected in the table (2nd and 3rd thereafter)
    `Point Biserial or Pearson` = cell_spec(`Point Biserial or Pearson`, "latex", color = ifelse(`Point Biserial or Pearson` < 0.000, "red", 
                                                                                                 ifelse(`Point Biserial or Pearson` < disc.threshold, "blue", "black"))),
    `Lower CI` = cell_spec(`Lower CI`, "latex", color = ifelse(`Lower CI` < 0.000, "red",
                                                                                 ifelse(`Lower CI` < disc.threshold, "blue", "black"))),
    `Upper CI` = cell_spec(`Upper CI`, "latex", color = ifelse(`Upper CI` < 0.000, "red",
                                                                                 ifelse(`Upper CI` < disc.threshold, "blue", "black"))),
    `Bi- or Poly-serial` = cell_spec(`Bi- or Poly-serial`, "latex", color = ifelse(`Bi- or Poly-serial` < 0.000, "red",
                                                                                   ifelse(`Bi- or Poly-serial` < disc.threshold, "blue", "black")))
    ) %>%
  dplyr::select(`Item Abbreviation`, `Point Biserial or Pearson`, `Lower CI`, `Upper CI`, `Bi- or Poly-serial`) %>%
  kable(format="latex", escape = F, booktabs = T, linesep = "", align='cc', caption= "Point-Biserial/Pearson, and Bi-/Poly-Serial Discrimination Indices", longtable=T) %>%
  kable_styling(latex_options = c("striped", "repeat_header"), font_size = 11) %>%
  footnote(general = "Correlations under predefined limit (if any) in blue while negative values (if any) in red.")

if (params$rendered_by_shiny){
  shiny::setProgress(0.48)
}
```
  
\newpage

### 4.4 Itemfit for the `r Construct` Items
The itemfit (un-weighted and weighted mean square) fit indices for the `r ncol(resp)` `r Construct` items are provided in Table 5. Item infit and outfit *t* statistics and *p* values are also included.  


```{r CHUNK25_Item_fit_table, echo=FALSE, fig.height=7, fig.width=10, message=TRUE, warning=FALSE}
round.item.fit.stats  %>%                                                           
  dplyr::mutate(
    `Item Abbreviation` = round.item.fit.stats$`Item Abbreviation`,
    `Outfit` = round.item.fit.stats$Outfit,
    `Outfit t` = cell_spec(`Outfit t`, "latex", color = ifelse(`Outfit t` >= 1.96 | `Outfit t` < -1.96, "red", "black")),
    `Outfit p` = round.item.fit.stats$`Outfit p`,
    `Infit` = round.item.fit.stats$Infit,
    `Infit t` = cell_spec(`Infit t`, "latex", color = ifelse(`Infit t` >= 1.96 | `Infit t` < -1.96, "red", "black")),
    `Infit p` = round.item.fit.stats$`Infit p`
  ) %>%
  dplyr::select(`Item Abbreviation`, Outfit, `Outfit t`, `Outfit p`, Infit, `Infit t`, `Infit p`) %>%
  kable(format="latex", escape = F, booktabs = T, linesep = "", align='cc', caption= "Item-fit Statistics", longtable=T) %>%
  kable_styling(latex_options = c("striped", "repeat_header"), font_size = 11) %>%
  footnote(general = "Statistically significant results (equal to or above t = |1.96|) are highlighted in red.") 

if (params$rendered_by_shiny){
  shiny::setProgress(0.50)
}
```

\newpage

```{r CHUNK26_Outfit_stats, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE, results="hide"}
#### Graph outfit stats ####
Outfit <- as.numeric(round(item.fit.mod1$itemfit$Outfit, 2))
Outfit.data <- cbind.data.frame(Item.Names, Outfit)
Outfit.data$Item.Names <- factor(Outfit.data$Item.Names, levels = Outfit.data$Item.Names)

#### Identify sum of outfit stats over limit ####
Item.n.over.outfit.limit <- sum(Outfit >= Theoretical.mnsq.max)

#### Replace sum for APA conventions ####
if(Item.n.over.outfit.limit > 0 & Item.n.over.outfit.limit < 10){
 Item.n.over.outfit.limit <- as.character(english::as.english(Item.n.over.outfit.limit))
}

#### If still happens to be '0', then replace with "none" for language coherence in text ####
if(Item.n.over.outfit.limit == 0){
   Item.n.over.outfit.limit <- "none"
}

if (params$rendered_by_shiny){
  shiny::setProgress(0.52)
}
```

```{r CHUNK27_Fit_language, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE, results="hide"}
##### Outfit stat language ####
Infit <- as.numeric(round(item.fit.mod1$itemfit$Infit, 2))
Infit.data <- cbind.data.frame(Item.Names,Infit)
Infit.data$Item.Names <- factor(Infit.data$Item.Names, levels = Infit.data$Item.Names)

#### Identify sum of infit stats over limit ####
Item.n.over.infit.limit <- sum(Infit >= Theoretical.mnsq.max)

#### Replace sum for APA conventions ####
if(Item.n.over.infit.limit > 0 & Item.n.over.infit.limit < 10){
   Item.n.over.infit.limit <- as.character(english::as.english(Item.n.over.infit.limit))
}

#### If still happens to be '0', then replace with "none" for language coherence in text ####
if(Item.n.over.infit.limit == 0){
   Item.n.over.infit.limit <- "none"
}

#### Identify grand maximum y value for both infit and outfit graphs ####
full.fit.vector <- c(Outfit, Infit, Theoretical.mnsq.max)
y.limit <- max(full.fit.vector) + 0.03

if (params$rendered_by_shiny){
    shiny::setProgress(0.54)
}
```

The item outfit statistics are also graphed in Figure 1. In accordance with Formula 7, the red lines on the graph illustrate the upper- and lower-bound 95% confidence intervals for item outfit distribution (these values are `r round(Theoretical.mnsq.max, 2)` and `r round(Theoretical.mnsq.min, 2)`, respectively). As illustrated by Figure 1, of the `r ncol(resp)` items in the instrument, `r Item.n.over.outfit.limit` were over the upper-bound confidence interval for the outfit distribution.  
  
\vspace{1mm}

```{r CHUNK28_Outfit_graph, echo=FALSE, fig.height=6, fig.width=10, message=TRUE, warning=FALSE, include=TRUE}
ggplot(Outfit.data, aes(x = Item.Names, y = Outfit)) +
  geom_bar(stat = "identity", fill=color.palette) + 
  geom_text(aes(label=Outfit), vjust=-0.3, color="black", size=2.0) +
  ggtitle("") + 
  xlab("Items") + 
  ylab("Outfit MNSQ") + 
  theme(plot.title = element_text(hjust = 0.5, size=8)) +
  scale_x_discrete(labels=Item.Names) +
  theme(axis.title.y = element_text(size=12), 
        axis.title.x = element_text(size=12),
        axis.text = element_text(size=8),
        panel.background = element_rect(fill = "grey85", colour = "white")) +
  geom_hline(yintercept = Theoretical.mnsq.min, color = "red") +
  geom_hline(yintercept = Theoretical.mnsq.max, color = "red") +
  theme(axis.text.x = element_text(angle=60,hjust=1))  +
  scale_y_continuous(limits=c(0, y.limit), oob = rescale_none)

if (params$rendered_by_shiny){
   shiny::setProgress(0.56)
}
```
  
**Figure 1. Unweighted Fit Statistics**  
Note. Red lines are upper and lower 95% CIs for the outfit distribution.   

\newpage

The item infit statistics are also graphed in Figure 2. In accordance with Formula 7, the red lines on the graph illustrate the upper- and lower-bound 95% confidence intervals for item infit distribution (these values are `r round(Theoretical.mnsq.max, 2)` and `r round(Theoretical.mnsq.min, 2)`, respectively). As illustrated by Figure 2, of the `r ncol(resp)` items in the instrument, `r Item.n.over.infit.limit` were over the upper-bound confidence interval for the infit distribution.  
  
\vspace{1mm}

```{r CHUNK30_Infit_graph, echo=FALSE, fig.height=6, fig.width=10, message=TRUE, warning=FALSE, include=TRUE, results="hide"}
ggplot(Infit.data, aes(x = Item.Names, y = Infit)) +
  geom_bar(stat = "identity", fill = color.palette) + 
  geom_text(aes(label = Infit), vjust = -0.3, color = "black", size = 2.0) +
  ggtitle("") + 
  xlab("Items") + 
  ylab("Infit MNSQ") + 
  theme(plot.title = element_text(hjust = 0.5, size = 8)) +
  scale_x_discrete(labels = Item.Names) +
  theme(axis.title.y = element_text(size = 12), 
        axis.title.x = element_text(size = 12),
        axis.text = element_text(size = 8),
        panel.background = element_rect(fill = "grey85", colour = "white")) +
  geom_hline(yintercept = Theoretical.mnsq.min, color = "red") +
  geom_hline(yintercept = Theoretical.mnsq.max, color = "red") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  scale_y_continuous(limits = c(0, y.limit), oob = rescale_none)

if (params$rendered_by_shiny){
    shiny::setProgress(0.60)
}
```
  
**Figure 2. Weighted Fit Statistics**  
Note. Red lines are upper and lower 95% CIs for the outfit distribution.  

In addition, the model deviance was estimated at `r model.deviance`.  

\newpage
  
The alpha if item deleted ($\alpha_{deleted}$) values are provided in Figure 3. To note, the alpha value for the full set of `r ncol(resp)` items is `r round(r$alpha,4)`. If the $\alpha_{deleted}$ values are more than the full alpha value, that is evidence that the item does not contribute to the test and should be removed. For a final level of analysis of item functioning, the full item correlation matrix could be inspected for incidences of negative correlations between problematic item(s) and other items in the test instrument (Appendix A1). Incidences of negative correlations could be seen as evidence of poor item functioning and could be further investigated. An inspection of the CTT Item Analysis (itenal; Appendix A3) may also be undertaken.  

\vspace{3mm}

\newpage  
  
```{r CHUNK31_Alpha_data, echo=FALSE, fig.height=6, fig.width=10, message=TRUE, warning=FALSE, include=TRUE, results="hide"}
#### CTT Alpha if deleted data ####
alpha1 <- round(r$alpha, 4)
alphaIfDeleted <- round(r$alphaIfDeleted, 4)
alphaIfDeleted2dp <- round(r$alphaIfDeleted, 2)

#### Let's create a single vector that includes alpha (based on all variables) and the alphaIfDeleted vector ####
# (the max value of this thorough vector should inform the max of the y value for graph)
full.alpha.vector <- c(alpha1, alphaIfDeleted)

#### Create dataframe ####
alpha.data <- cbind.data.frame(Item.Names, alphaIfDeleted)

#### Generate max and min y values (includes actual full reliability in upper alpha) ####
lower.alpha_minus.05 <- min(alphaIfDeleted) - .005
upper.alpha_plus.05 <- max((full.alpha.vector) + .005, alpha1 + .005)

alpha.data$Item.Names <- factor(alpha.data$Item.Names, levels = alpha.data$Item.Names)

#### Generate graph ####
ggplot(alpha.data, aes(x = Item.Names, y = alphaIfDeleted)) +
  geom_bar(stat = "identity", fill = color.palette) + 
  geom_text(aes(label = alphaIfDeleted2dp), vjust = -0.3, color = "black", size = 2) +
  ggtitle("") + 
  xlab("Items") + 
  ylab("Alpha if Deleted") + 
  theme(plot.title = element_text(hjust = 0.5, size = 18)) + 
  scale_x_discrete(labels = Item.Names) +
  scale_y_continuous(limits = c(lower.alpha_minus.05, upper.alpha_plus.05), oob = rescale_none) +
  theme(axis.title.y = element_text(size = 15), 
        axis.title.x = element_text(size = 15),
        axis.text = element_text(size = 8),
        axis.text.x = element_text(angle = 60, hjust = 1),
        panel.background = element_rect(fill = "grey85", colour = "white")) +
  geom_hline(yintercept = alpha1, color="red", cex = .5)

if (params$rendered_by_shiny){
    shiny::setProgress(0.62)
}
```
**Figure 3. The Alpha Full Minus the Alpha Deleted Values**  
Note. The red line is the $\alpha$ estimate for all items, i.e., `r alpha1`; illustrated alpha-if-deleted values positionally accurate but rounded to two decimal places.  
  
\newpage

### 4.5 Results for IRT Student Ability and Item Difficulty Estimates  
Based on the MML analysis, the mean ability (logit) of the sample of interest was `r mean.EAP.person` (analysis was centred on items). The `r Construct` logits ranged from `r EAP.min` to `r EAP.max` and the standard deviation was `r EAP.SD`.  
  
The item difficulties (deltas) had a mean of `r mean.item.diff` and a standard deviation of `r sd.item.diff`. The difficulty logits for each respective item are provided in Table 6 (the full set of item difficulties for each item's di- or poly-chotomous category is provided in Appendix A2).  
  
```{r CHUNK32_Item_difficulty, echo=FALSE, fig.height=12, fig.width=16, message=TRUE, warning=FALSE}
kable(item.diff.df, format = "latex", booktabs = T, align = 'cc', caption = "Item Difficulties", longtable = T) %>% 
  kable_styling(latex_options = c("striped", "scale_down", "repeat_header"), font_size = 11)

if (params$rendered_by_shiny){
    shiny::setProgress(0.64)
}
```
  
The Cronbach's alpha was `r round(Cronbachs,2)` and the population-related MML reliability estimate was `r round(mod1$EAP.rel,2)` (Wu, Tam, and Jen, 2016).

\newpage 
### 4.6 Wright Map  
The Wright Map is presented in Figure 4. It should be noted that EAP ability estimates are used for student ability and item difficulty in this instance.  
\vspace{5mm}  
   
\vspace{5mm}
  
```{r CHUNK33_Wright_Map, echo=FALSE, fig.height=7, fig.width=10, message=TRUE, warning=FALSE}
ggWrightMapnew(mod1$person$EAP, thr.v, binwidth = binwidth, size=12, color = color.palette[1], item.names = names) # note thr.v and names exported in xlsx file.

if (params$rendered_by_shiny){
    shiny::setProgress(0.66)
}
```
**Figure 4. The Wright Map**  
  
\newpage  
### 4.7 Item Expected Score Curves  
Following are a set of graphs illustrating all item expected score curves. Thereafter, Table 7 provides list of the associated Thurstonian thresholds for each item, the point at which the probability of reaching that score or higher is p .50. Thurstonian thresholds are useful representations of item difficulty when the items have different scoring categories (Wu, 2016). 
  
\vspace{2mm}

```{r CHUNK34_Expected_curves, echo=FALSE, fig.height=6, fig.width=10, message=TRUE, warning=FALSE, trace=FALSE, results="hide"}
knitr::opts_chunk$set(echo = FALSE)
plot(mod1, type = "expected")

if (params$rendered_by_shiny){
    shiny::setProgress(0.68)
}
```

\newpage
### 4.8 Polytomous Item Category Characteristic Curves  
Following are a set of graphs illustrating all item category characteristic curves.  
\vspace{2mm}
```{r CHUNK35_Cat_char_curves, echo=FALSE, fig.height=6, fig.width=10, message=TRUE, warning=FALSE, results="hide"}
knitr::opts_chunk$set(echo = FALSE)
plot(mod1, type = "items", lwd = 4)

if (params$rendered_by_shiny){
    shiny::setProgress(0.70)
}
```

\newpage

### 4.9 Thurstonian Thresholds  
The Thurstonian Thresholds are presented in Table 7.  
  
```{r CHUNK36_Thresholds, echo=FALSE, fig.height=12, fig.width=16, message=TRUE, warning=FALSE}
#### Necessarily change to dataframe before using sapply function ####
thr <- as.data.frame(thr)

#### replace NAs with blanks for visual for table ####
thr <- sapply(thr, as.character)
thr[is.na(thr)] <- ""
rownames(thr) <- colnames(resp)
kable(thr, format = "latex", booktabs = T, align = 'cc', caption = "Thurstonian Thresholds", longtable = T) %>%
  kable_styling(latex_options = c("striped", "repeat_header", font_size = 11)) 

if (params$rendered_by_shiny){
    shiny::setProgress(0.72)
}
```

\newpage

## 5. REFERENCES
Adams, R. J. Wu, M. L., & Wilson, M. R. (2019). *ACER ConQuest: GeneralisedItem Response Modelling Software [Computer software]. Version 4*. Camberwell, Victoria: Australian Council for Educational Research.  
  
Bock, R. D., & Aitkin, M. (1981). Marginal maximum likelihood estimation of item parameters: Application of an EM algorithm. *Psychometrika 46*,443–59.  
  
Brennan, R. L. (2001). *Generalizability Theory*. New York: Springer-Verlag.  
  
Cohen, J. (1992). A power primer. *Psychological Bulletin*, 112, 155-159. doi:10.1037/0033-2909.112.1.155  
  
Cohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003). *Applied multiple regression/correlation analysis for the behavioral sciences (3rd ed.)*. Mahwah, NJ: Lawrence Erlbaum.  
  
Cronbach, L. J. (1951). Coefficient alpha and the internal structure of tests. *Psychometrika, 16*(3), 297-334. doi:10.1007/BF02310555  
  
Dahl, B. D., Scott, D., Roosen, C., Magnusson, A., & Swinton, J. (2018). xtable: Export Tables to LaTeX or HTML. R package version 1.8-3. Downloaded from https://CRAN.R-project.org/package=xtable  
  
DeVellis, R. F. (2012). Scale Development: Theory and Applications. Thousand Oaks, LA: Sage.  
  
Harrell, F. & Dupont, C. (2018). Hmisc: Harrell Miscellaneous. R package version 4.1-1. Downloaded from https://CRAN.R-project.org/package=Hmisc  
  
Laukaityte, I. & Marie Wiberg, M. (2017) Using plausible values in secondary analysis in large-scale assessments. *Communications in Statistics - Theory and Methods, 46*(22), 11341-11357. doi.10.1080/03610926.2016.1267764  
  
Masters, G. N. (1982). A Rasch model for partial credit scoring. *Psychometrika, 47(2), 149-174.  
  
Masters, G. N. (1988). Item Discrimination: When More is Worse. *Journal of Educational Measurement, 25*(1), 15-29.  
  
Muraki, E. (1993). Information functions of the generalized partial credit model. *Applied Psychological Measurement, 17*(4), 351-363.  
  
Olsson, U., Drasgow, F., & Dorans, N. J. (1982). The polyserial correlation coefficient. *Biometrika, 47*, 337–347.  
  
Revelle, W. (2018). *psych: Procedures for Personality and Psychological Research, Version = 1.8.4*. Northwestern University, Evanston, Illinois, USA. Retreived from https://CRAN.R-project.org/package=psych  
  
Robitzsch, A., Kiefer, T., & Wu, M. (2018). *TAM: Test analysis modules. R package version 2.10-24*. Retreived from  https://CRAN.R-project.org/package=TAM  
Martinková, P., & Drabinová, A. (2018). ShinyItemAnalysis for Teaching Psychometrics and to Enforce Routine Analysis of Educational Tests. *The R Journal*, 10(2), 503-515. doi: 10.32614/RJ-2018-074  
  
Warm, T. A. (1989). Weighted likelihood estimation of ability in item response theory. *Psychometrika, 54*, 427-450.  
  
Willse, J. T. (2018). *CTT: Classical Test Theory Functions. R package version 2.3.2*. Retreived from https://CRAN.R-project.org/package=CTT  
  
Wu, M. (2005). The role of plausible values in large-scale surveys. *Studies in Educational Evaluation, 31*(2-3), 114-128. doi:10.1016/j.stueduc.2005.05.005  
Wu, M. & Adams, R. J. (2013). Properties of Rasch residual fit statistics. *Journal of Applied Measurement, 14*(4), 339-355.  
  
Wu, M., Tam, H. P., & Jen, T-H. (2016). *Educational Measurement for Applied Researchers: Theory into Practice*. Singapore: Springer Nature.  
  
\newpage
  
## 6. APPENDICES  
\newpage  
## A1. Correlational Heatmap Matrix  
*Note*. This matrix provides visual insight into incidences of negative correlations between items. Neutral (zero) Pearson correlation coefficients in white whilst negative correlations in red. Appendix A2 provides a full correlational matrix with specific values and levels of statistical significance.  
  
```{r CHUNK37_Corr_Matrix, echo=FALSE, message=TRUE, warning=FALSE}
options(width=170) # seems to work well retaining most numeric information

#### Need to identify correlation matrix with no stars ####
heatmap.matrix <- round(cor(resp, use="pairwise.complete.obs"),3)

#### Reshape data ####
melted_cormat <- reshape2::melt(heatmap.matrix, na.rm=TRUE)
melted_cormat$Var1 <- as.factor(melted_cormat$Var1)
melted_cormat$Var2 <- as.factor(melted_cormat$Var2)

#### Heatmap ####
ggplot(data = melted_cormat, aes(Var2, Var1, fill = value)) +
  geom_tile(color="white") +
  scale_fill_gradient2(low = "red", high = "blue", mid = "white", midpoint = 0, limit = c(-1,1), space = "Lab", name="Pearson\nCorrelation")

#### sum negaitve elements in matrix ####
number.neg.elem <- (sum(heatmap.matrix < 0, na.rm = TRUE))/2
total.elements <- (ncol(resp) * (ncol(resp)-1)) /2

#### Replace sum for APA conventions ####
if(number.neg.elem > 0 & number.neg.elem < 10){
   number.neg.elem <- as.character(english::as.english(number.neg.elem))
}

#### If still happens to be '0', then replace with "none" for language coherence in text ####
if(number.neg.elem == 0){
   number.neg.elem <- "none"
}

if (params$rendered_by_shiny){
    shiny::setProgress(0.74)
}
``` 
  
**Figure 5. The Correlational Heatmap Matrix**  
Note. Negative correlations (if any) in red represent unexpected relationships between items of interest; in addition, of the total `r total.elements` elements in the lower triangle (no counting 1s), `r number.neg.elem` were negative; in the presence of missing data, pairwise complete observations used.  
 
```{r CHUNK38_Optional_Heatmap, echo=FALSE, message=FALSE, warning=FALSE}
#### For html options, developer may like to explore... ####

#  upper.triangle <- flip.matrix(upper.triangle)
#  diag(upper.triangle) <- NA

#  plot_ly(z = upper.triangle) %>% 
#  add_surface() %>%
#  layout(
#   scene = list(
#     camera=list(
#       eye = list(x=-1.80, y=3.88, z=1.50)
#       )
#     )
#  )
``` 
 
 
\newpage  
## A2. Full Pearson Correlation Matrix  
**Note.** The following is a correlation matrix illustrating all possible correlations between items in the `r Construct` instrument; matrices are subsetted by columns left to right; the final row under the lower triangle matrix illustrates all possible item-total correlations(Row_Totals) with the item of interest's contribution included in the total (compare with item-rest correlations in Table 4 which have a bias toward $r=|1.0|$). Note that for each correlation in the matrix, $p<.0001^{****}; p<.001^{***}; p<.01^{**}; p<.05^{*}; p\geq.05$, is considered not statistically significant.  
\vspace{5mm}  
   
\vspace{5mm}
  
\fontsize{8}{8}  
  
```{r CHUNK39_Print_corr_matrix, echo=FALSE, message=TRUE, warning=FALSE}
options(width = 120) # seems to work well retaining most information
print(matrix.r.p)

if (params$rendered_by_shiny){
    shiny::setProgress(0.78)
}
``` 
  
\newpage  
  
\fontsize{14}{12}  
  
## A3. The Item Delta Estimates  
Note that in the Table 8, N represents the number of person responses for that item, M represents the mean raw score across all persons for that item, xsi represent the item deltas for that item, AXsi values represent the point at which adjacent score categories have equal probability; and s.e. represents the estimated standard error of associated with the item of interest. Note that it is normal for some disorderedness when the probability of reaching a middle category is small (where few persons reached that category). For a complete discussion, see Wu, Tam, & Jen (2016, pp. 162-165).  
  
\vspace{5mm}  
   
\vspace{5mm}
  
```{r CHUNK40_Item_Deltas, echo=FALSE, fig.height=7, fig.width=10, message=TRUE, warning=FALSE}
Item.cat.param <- round(mod1$item[, -1], 2)    # removes first column (but not row names)

#### Take out final four columns as redundant ####
cols.to.delete <- max(resp, na.rm=TRUE)                          # identify number of final columns to delete 
cols.item.param <- ncol(Item.cat.param)              # identify number of total columns
cols.necessary <- cols.item.param - cols.to.delete   # identify number of remaining columns
Item.cat.param <- Item.cat.param[, 1:cols.necessary]  # subset only those necessary

#### Include standard errors ####
s.e. <- round(mod1$xsi[1:ncol(resp), 2], 2) 
Item.cat.param <- cbind.data.frame(Item.cat.param, s.e.)

#### replace NAs with blanks for visual for table ####
Item.cat.param <- sapply(Item.cat.param, as.character)
Item.cat.param[is.na(Item.cat.param)] <- ""
rownames(Item.cat.param) <- colnames(resp)

kable(Item.cat.param, format = "latex", booktabs = T, align = 'cc', caption = "Item Delta Parameters", longtable = T) %>%
  kable_styling(latex_options = c("striped", "scale_down", "repeat_header"), font_size = 11)

if (params$rendered_by_shiny){
    shiny::setProgress(0.80)
}
```
  
  
\newpage
  
## A4. CTT Item Analysis  
Results of the CTT item analysis suggested that, of the total `r all.categories` categories in the instrument, `r total.disordered` exhibited disorderedness (see in red, below).  

```{r CHUNK41_CTT_Item_Analysis, echo=FALSE, fig.height=7, fig.width=10, message=TRUE, warning=FALSE}
ctt_raw.df %>%                                                           
  dplyr::mutate(                                        # mutate function enables the piping of extra coloring info into the table
    Item = ctt_raw.df$Item,                             # simply defines the first column of the variable to be selected in the table (2nd and 3rd thereafter)
    Total = ctt_raw.df$Total,  
    Category = ctt_raw.df$Category,    
    Count = ctt_raw.df$Count,
    Percent = ctt_raw.df$Percent,
    Pbs = cell_spec(Pbs, "latex", color = ifelse(`Disorderedness T/F` == TRUE, "red", "black")),
    `Disorderedness T/F` = ctt_raw.df$`Disorderedness T/F`,
    MeanAbility = ctt_raw.df$MeanAbility
    ) %>%
    dplyr::select(Item, Total, Category, Count, Percent, Pbs, MeanAbility) %>%
    kable(format = "latex", escape = F, booktabs = T, linesep = "", align = 'cc', caption = "CTT Item Analysis", longtable = T) %>%
    kable_styling(latex_options = c("striped", "repeat_header"), font_size = 9) %>%
    footnote(general = "Disorderedness point bi-serials, where lower category correlation is larger (toward 1.00), in red.")

#* Note: Alternate table with CIs

#ctt_raw.df %>%                                                           
#  dplyr::mutate(                                                                                         # mutate function enables the piping of extra coloring info into the table
#    Item = ctt_raw.df$Item,                                                                              # simply defines the first column of the variable to be selected in the table (2nd and 3rd thereafter)
#    Total = ctt_raw.df$Total,  
#    Category = ctt_raw.df$Category,    
#    Count = ctt_raw.df$Count,
#    Percent = ctt_raw.df$Percent,
#    Pbs = cell_spec(Pbs, "latex", color = ifelse(`Disorderedness T/F` == TRUE, "red", "black")),
#    `Disorderedness T/F` = ctt_raw.df$`Disorderedness T/F`,
#    `Lower 95 CI` = ctt_raw.df$`Lower 95 CI`,
#    `Upper 95 CI` = ctt_raw.df$`Upper 95 CI`,
#    MeanAbility = ctt_raw.df$MeanAbility
#    ) %>%
#    dplyr::select(Item, Total, Category, Count, Percent, Pbs, `Lower 95 CI`, `Upper 95 CI`, MeanAbility) %>%
#    kable(format="latex", escape = F, booktabs = T, linesep = "", align='cc', caption= "CTT Item Analysis", longtable=T) %>%
#    kable_styling(latex_options = c("striped", "repeat_header"), font_size = 9) %>%
#    footnote(general = "Disorderedness point bi-serials, where lower category correlation is larger (toward 1.00), in red.")

if (params$rendered_by_shiny){
    shiny::setProgress(0.82)
}
```
 
 
\newpage  
## A5. Test Information and Standard Error Curve Graph  
```{r CHUNK43_Test_info_and_se, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
imod1 <- TAM::IRT.informationCurves(mod1)

#### Identify theta test info min and max ####
TI.lower <- round(imod1$test_info_curve[1], 3)
TI.max <- max(imod1$test_info_curve)
TI.max.r <- round(max(imod1$test_info_curve), 3)
TI.upper <- round(imod1$test_info_curve[length(imod1$test_info_curve)], 3)

#### Identify theta with max information ####
max.position <- match(TI.max, imod1$test_info_curve)
max.theta <- round(imod1$theta[max.position], 3)

#### Identify theta SEs min and max ####
SE.lower <- round(imod1$se_curve[1], 3)
SE.min.r <- round(min(imod1$se_curve), 3)
SE.upper <- round(imod1$se_curve[length(imod1$se_curve)], 3)

#### Generate scale modifier for SE uppscale ####
SE.scale.multiplier <- max(imod1$test_info_curve) / max(imod1$se_curve)
upscales.SEs <- imod1$se_curve * SE.scale.multiplier

#### wrangle data ####
info.plus.se.df <- cbind.data.frame(imod1$test_info_curve, upscales.SEs, as.numeric(imod1$theta))
colnames(info.plus.se.df) <- c("Information", "SE", "Theta")

if (params$rendered_by_shiny){
    shiny::setProgress(0.86)
}
```
  
The test information and standard error curve graph is presented in Figure 6. Test information at the lower end of theta was estimated at `r TI.lower` whilst test information at the higher end was estimated at `r TI.upper`. Test information was maximised where $\theta$=`r max.theta` (test information = `r TI.max.r`). The standard errors for theta (which have an inverse relationship to the test information) are also presented in Figure 5. The standard error at the lower end of theta was estimated at `r SE.lower` and at the higher end of theta was `r SE.upper`, and, where test information was maximised, the minimum standard error was `r SE.min.r`.  
  
\vspace{5mm}  
   
\vspace{5mm}
```{r CHUNK44_Print_test_info_and_se, echo=FALSE, fig.height=4, fig.width=10, message=TRUE, warning=FALSE}
suppressMessages(
ggplot(info.plus.se.df, aes(x=Theta)) + 
  ylim(0, max(info.plus.se.df$Information)) +
  geom_line(aes(y = Information), color="blue") + 
  geom_line(aes(y = SE), color="red") +
  scale_y_continuous(sec.axis = sec_axis(~.*(1/SE.scale.multiplier), name = "Standard Error")) + 
  theme(legend.position="right", panel.background = element_rect(fill = "grey85", colour = "white")) +
  ylab("Test Information")   
)

if (params$rendered_by_shiny){
  shiny::setProgress(0.88)
}
``` 
  
**Figure 6. Test Information and Standard Error Curve**  
Note. Test information curve in blue; standard error curve in red; graphs created in accordance with Muraki (1993).     
\newpage  
  
## A6. Personfit Statistics  
```{r CHUNK45_Person_fit_narration, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
#### Extract min and max ####
min.person.fit <- min(ordered_resp$Person_fit_stats)
max.person.fit <- max(ordered_resp$Person_fit_stats)

#### Identify percentage poor fitting persons above personfit threshold ####
sum.over.pfit <- sum(ordered_resp$Person_fit_stats > p.fit.threshold)

#### Change sum to percent ####
percent.high.pfit <- round((sum.over.pfit/nrow(resp))*100,2)

#### Replace sum for APA conventions ####
if(sum.over.pfit > 0 & sum.over.pfit < 10){
   sum.over.pfit <- as.character(english::as.english(sum.over.pfit))
}

#### If still happens to be '0', then replace with "none" for language coherence in text ####
if(sum.over.pfit == 0){
   sum.over.pfit <- "none"
}

#### If none or one, alter grammar of "... one/none had a person fit value..." ####
p.fit.grammar <- "person fit values above"                   # for standard result assuming multiple persons with person fit values above threshold

if(sum.over.pfit == "none"|sum.over.pfit == "one"){          # introduces alternative for singleton or none
   p.fit.grammar <- "a person fit value above"
}

if (params$rendered_by_shiny){
    shiny::setProgress(0.90)
}
```

Results for the mean square person fit are presented in Figure 7. The minimum person fit was `r round(min.person.fit, 2)` and the maximum person fit was `r round(max.person.fit, 2)`. Of the total `r nrow(resp)` respondents, `r sum.over.pfit` (`r percent.high.pfit`%) had `r p.fit.grammar` `r round(p.fit.threshold,2)`. To note, an outputted csv file with individual student IDs personfit estimates and respective ability scores was generated as part of this report and can be used to identify atypical respondents (this file may be obtained by contacting the main author).  

\vspace{5mm}  

   
```{r CHUNK46_Print_person_fit, echo=FALSE, fig.height=4, fig.width=10, message=TRUE, warning=FALSE}
qplot(seq_along(ordered_resp$Person_fit_stats), ordered_resp$Person_fit_stats) +
  geom_point(color = color.palette[1] , size = 0.05) + 
  ylab("Person Outfit MNSQ") +                           
  xlab("Students") +                                  
  ggtitle("") +  
  theme(plot.title = element_text(hjust = 0.5, size = 20),
        axis.title.y = element_text(size = 15),
        axis.title.x = element_text(size = 15),
        axis.text = element_text(size = 10),
        panel.background = element_rect(fill = "grey85", colour = "white")) +
  geom_hline(yintercept = p.fit.threshold, color = "red") +
  geom_hline(yintercept = Theoretical.mnsq.minP, color = "blue") +
  geom_hline(yintercept = Theoretical.mnsq.maxP, color = "blue") 

if (params$rendered_by_shiny){
    shiny::setProgress(0.92)
}
```
**Figure 7. Personfit Statistics (Ordered Descendingly)**  
Note. Blue lines represent 95% CIs.  
  
The lower and uppoer 95% confidence intervals for the person fit statistics were `r Theoretical.mnsq.minP` and `r Theoretical.mnsq.maxP`, respectively.  
  
\newpage 

## A7. Missing Value Analysis  
Table 10 presents the final results for the missing value analysis. 
  
```{r CHUNK47_Basic_MVA, echo=FALSE, message=TRUE, warning=FALSE}
column.names <- colnames(resp)
missing.counts <- apply(resp, 2, FUN = function(x)sum(is.na(x)))
missing.counts <- unname(missing.counts)
perc.missing <- round((missing.counts/nrow(resp)*100), 1)

missingness.df <- cbind.data.frame(column.names, missing.counts, perc.missing)
row.names(missingness.df) <- NULL
colnames(missingness.df) <- c("Item Name", "Count of Missing Values", "Percent Missing")

kable(missingness.df, format = "latex", booktabs = T, align = 'cc', caption = "Missingness for Each Item", longtable = T) %>%
  kable_styling(latex_options = c("striped","repeat_header"), font_size = 11) #%>%

if (params$rendered_by_shiny){
    shiny::setProgress(0.94)
}
```
  
```{r CHUNK48_Compile_xlsx_output, echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE, include=FALSE}
#### Person stats ####
Person.stats <- cbind.data.frame(mod1$person, tam.person.fit.stats$outfitPerson)
colnames(Person.stats) <- c("Participant ID", "Case", "Person weight", "Score", "Max score", "Ability (theta)", "Standard error", "Person-fit (outfit)")

#### Ordered person stats ####
Person.stats.o <- Person.stats[order(Person.stats$`Ability (theta)`, decreasing = T), ]

#### Item difficulty and SE stats ####
Item.details <- cbind.data.frame(rownames(mod1$xsi), mod1$xsi)
colnames(Item.details)[1] <- "Item/Item Step"
rownames(Item.details) <- NULL

#### Item thresholds ####
thr.df <- as.data.frame(thr)
thr.df <- cbind.data.frame(rownames(thr.df), thr.df)
rownames(thr.df) <- NULL

#### Item threshold vector ####
Thresh.vec <- cbind.data.frame(names, thr.v)
Thresh.vec <- Thresh.vec[order(Thresh.vec$thr.v, decreasing = T), ]
colnames(Thresh.vec) <- c("Item names (and step category)", "Threshold")

#### Frequency of categories ####
freq.df <- as.data.frame(freq.uneven)
freq.df <- apply(freq.df, 2, function(x)as.numeric(x))
freq.df <- as.data.frame(freq.df)
freq.df <- cbind.data.frame(disc.disc1$`Item Abbreviation`, freq.df)
colnames(freq.df)[1] <- "Item Names"

#### Pearson Correlation Matrix ####
matrix.r.p <- cbind.data.frame(rownames(matrix.r.p), matrix.r.p)
colnames(matrix.r.p)[1] <- "Item Names"
rownames(matrix.r.p) <- NULL

##### COMPILE #####
list.of.data <- list("Ordered Person Results" = Person.stats.o, "Ordered Item Difficulties(thresholds)" = Thresh.vec, 
                     "Person Results" = Person.stats, "Item Results" = Item.details, "Item Thresholds" = thr.df, 
                     "Item Frequency Categories" = freq.df, "Item Discrimination" = disc.disc1,
                     "Item Fit Stats" = round.item.fit.stats, "Item Correlation Matrix" = matrix.r.p,
                     "CTT Item Analysis" = ctt_raw.df, "Plausible Values" = Plausible.values)

openxlsx::write.xlsx(list.of.data, file = "report.xlsx")

if (params$rendered_by_shiny){
    shiny::setProgress(0.96)
}
```
 
 
\newpage  


## A8. Summary of Input Paramters, Analysis, and Outputs
Table 11 provides a summary of focal information, settings, and technical outputs for the analysis undertaken for this report.  
 

```{r CHUNK49_Technical_summary, echo=FALSE, message=TRUE, warning=FALSE}
end.time <- Sys.time()

full.rep.time <- end.time - start.time
full.rep.time <- round(as.numeric(full.rep.time), 3)

mod.time_sec <- end.mod.t - start.mod.t
mod.time_sec <- round(as.numeric(mod.time_sec), 3)

node.sequence1 <- paste(min(node.sequence), " to ", max(node.sequence), " for length ", length(node.sequence), sep="")

options(scipen=999)
conv <- as.character(conv)

Input.setting <- c("Assessment Topic (construct)", "Target group (students)", "Total number of cases (students)", "Total number of items", "Cases Deleted Listwise for CTT?", "Internal Consistency (alpha)", "Reliability of test (EAP)", "Overall model deviance (measure of fit)", "Minimum item-rest correlation", "CI level for item-rest cor", "Minimum person fit", "Model Type", "Model constraint", "Number of dimensions", "Assumed discretized population profile", "Maximum number of iterations (maxiter)","Convergence criterion for item parameters (conv)", "Build version of Shiny app", "Computation time for 1PLM model (sec)", "Computation time for full report (sec)")

Input.measure <- c(Construct, Population, nrow(resp), ncol(resp), NA.Delete, Cronbachs, EAP.reliability, model.deviance, disc.threshold, ci.level, p.fit.threshold, "1PLM", constraint, 
                   "1", node.sequence1, maxiter, conv, "1PLM_Auto-Psych_1.0", mod.time_sec, full.rep.time)

summary.df <- cbind.data.frame(Input.setting, Input.measure)
colnames(summary.df) <- c("Report Criteria", "Setting/Ouput")

kable(summary.df, format="latex", booktabs=T, align = 'l', caption = "Technical Settings for Report", longtable=T) %>%
  kable_styling(latex_options = c("striped","repeat_header"), font_size = 11)

if (params$rendered_by_shiny){
    shiny::setProgress(1)
}
# END
```



